{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded config module: <module 'config' from 'C:\\\\Users\\\\ak012\\\\Documents\\\\Projects\\\\config\\\\config.py'>\n",
      "Config attributes: ['COVERAGE_PENALTY_WEIGHT', 'MILESTONE_DAYS_THRESHOLD_3', 'MILESTONE_DAYS_THRESHOLD_5', 'MILESTONE_DAYS_THRESHOLD_7', 'MILESTONE_PENALTY_LESS_THAN_3_DAYS', 'MILESTONE_PENALTY_LESS_THAN_5_DAYS', 'MILESTONE_PENALTY_LESS_THAN_7_DAYS', 'MILESTONE_PENALTY_MORE_THAN_7_DAYS', 'OVERDUE_MULTIPLIER', 'RAISED_NOT_SENT_WEIGHT_FIRST_ELIF', 'RAISED_NOT_SENT_WEIGHT_FIRST_TOLERANCE_LEVEL', 'RAISED_NOT_SENT_WEIGHT_SECOND_ELIF', 'RAISED_NOT_SENT_WEIGHT_SECOND_TOLERANCE_LEVEL', 'RAISED_NOT_SENT_WEIGHT_ZERO', 'SCORE_THRESHOLD_GREEN', 'SCORE_THRESHOLD_YELLOW', 'STATUS_SCORE_COMPLETED', 'STATUS_SCORE_NOT_COMPLETED', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'validate_config']\n",
      "STATUS_SCORE_COMPLETED: 5\n",
      "STATUS_SCORE_NOT_COMPLETED: 20\n",
      "Number of invoices fetched: 42395\n",
      "Number of contracts fetched: 7652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ak012\\AppData\\Local\\Temp\\ipykernel_40140\\2091105988.py:148: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  parent_aggregated['weighted_interference_score'] = grouped_parent.apply(compute_parent_weighted_score).values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated parent company data saved to C:\\Users\\ak012\\Documents\\Projects\\Customers\\aggregated_parent_companies.xlsx\n",
      "Aggregated parent company data saved to C:\\Users\\ak012\\Documents\\Projects\\Customers\\aggregated_parent_companies.json\n",
      "Inserted 5353 documents into 'company_customers' collection.\n"
     ]
    }
   ],
   "source": [
    "# customers_processing.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timezone\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the absolute path to the config directory\n",
    "CONFIG_DIR = r'C:\\Users\\ak012\\Documents\\Projects\\config'\n",
    "\n",
    "# Add the config directory to sys.path if it's not already included\n",
    "if CONFIG_DIR not in sys.path:\n",
    "    sys.path.append(CONFIG_DIR)\n",
    "\n",
    "import config\n",
    "\n",
    "print(\"Loaded config module:\", config)\n",
    "print(\"Config attributes:\", dir(config))\n",
    "\n",
    "# Specifically check for the required attributes\n",
    "print(\"STATUS_SCORE_COMPLETED:\", getattr(config, 'STATUS_SCORE_COMPLETED', 'Not Found'))\n",
    "print(\"STATUS_SCORE_NOT_COMPLETED:\", getattr(config, 'STATUS_SCORE_NOT_COMPLETED', 'Not Found'))\n",
    "\n",
    "# MongoDB Connection Details\n",
    "MONGO_URI = \"Insert-here-",

    "DATABASE_NAME = \"legitt-prod\"\n",
    "INVOICES_COLLECTION = \"company_invoices\"\n",
    "CONTRACTS_COLLECTION = \"company_contracts\"\n",
    "\n",
    "# Function to calculate interference score\n",
    "def calculate_interference(row):\n",
    "    overdue_days = row['overdue_days']\n",
    "    status = row['status'].strip().lower()\n",
    "    if status == \"completed\":\n",
    "        status_score = config.STATUS_SCORE_COMPLETED\n",
    "    else:\n",
    "        status_score = config.STATUS_SCORE_NOT_COMPLETED\n",
    "    return overdue_days * config.OVERDUE_MULTIPLIER + status_score\n",
    "\n",
    "# Function to assign rating based on interference score\n",
    "def assign_rating(score):\n",
    "    if score < config.SCORE_THRESHOLD_GREEN:\n",
    "        return \"Green\"\n",
    "    elif config.SCORE_THRESHOLD_GREEN <= score < config.SCORE_THRESHOLD_YELLOW:\n",
    "        return \"Yellow\"\n",
    "    else:\n",
    "        return \"Red\"\n",
    "\n",
    "def process_invoices_and_contracts():\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient(MONGO_URI)\n",
    "    db = client[DATABASE_NAME]\n",
    "    invoices_collection = db[INVOICES_COLLECTION]\n",
    "    contracts_collection = db[CONTRACTS_COLLECTION]\n",
    "    customers_collection = db[\"company_customers\"]  # new collection for storing all rows\n",
    "\n",
    "    # Fetch data from MongoDB\n",
    "    invoices = list(invoices_collection.find())\n",
    "    contracts = list(contracts_collection.find())\n",
    "    print(f\"Number of invoices fetched: {len(invoices)}\")\n",
    "    print(f\"Number of contracts fetched: {len(contracts)}\")\n",
    "\n",
    "    # Convert data to DataFrames\n",
    "    df_invoices = pd.DataFrame(invoices)\n",
    "    df_contracts = pd.DataFrame(contracts)\n",
    "\n",
    "    # Ensure date columns are in datetime format\n",
    "    for col in ['due_date', 'from_date', 'to_date']:\n",
    "        df_invoices[col] = pd.to_datetime(df_invoices[col], errors='coerce')\n",
    "\n",
    "    # Handle timezone-aware dates\n",
    "    df_invoices['due_date'] = df_invoices['due_date'].apply(\n",
    "        lambda x: x.replace(tzinfo=timezone.utc) if pd.notnull(x) else x\n",
    "    )\n",
    "\n",
    "    # Calculate overdue days\n",
    "    today = datetime.now(timezone.utc)\n",
    "    df_invoices['overdue_days'] = df_invoices['due_date'].apply(\n",
    "        lambda x: max((today - x).days, 0) if pd.notnull(x) and x < today else 0\n",
    "    )\n",
    "\n",
    "    # Calculate interference score and rating\n",
    "    df_invoices['interference_score'] = df_invoices.apply(calculate_interference, axis=1)\n",
    "    df_invoices['rating'] = df_invoices['interference_score'].apply(assign_rating)\n",
    "\n",
    "    # Filter and aggregate invoices by contract\n",
    "    df_invoices_filtered = df_invoices[\n",
    "        ['contract_name', 'from_date', 'to_date', 'total_amount_in_usd', 'interference_score', 'rating']\n",
    "    ].copy()\n",
    "\n",
    "    # Avoid division errors\n",
    "    df_invoices_filtered['total_amount_in_usd'] = df_invoices_filtered['total_amount_in_usd'].replace(0, np.nan)\n",
    "\n",
    "    # Group data and calculate aggregates\n",
    "    aggregated_invoices = df_invoices_filtered.groupby(\"contract_name\").agg(\n",
    "        from_date=(\"from_date\", \"min\"),\n",
    "        to_date=(\"to_date\", \"max\"),\n",
    "        total_amount_in_usd=(\"total_amount_in_usd\", \"sum\"),\n",
    "        invoice_count=(\"contract_name\", \"size\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Weighted interference score\n",
    "    def calculate_weighted_interference(row):\n",
    "        contract_name = row['contract_name']\n",
    "        relevant_invoices = df_invoices_filtered[df_invoices_filtered['contract_name'] == contract_name]\n",
    "        total_amount = row['total_amount_in_usd']\n",
    "        if pd.notnull(total_amount) and total_amount > 0:\n",
    "            weighted_sum = (relevant_invoices['interference_score'] * relevant_invoices['total_amount_in_usd']).sum()\n",
    "            return weighted_sum / total_amount\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    aggregated_invoices['weighted_interference_score'] = aggregated_invoices.apply(calculate_weighted_interference, axis=1)\n",
    "    aggregated_invoices['rating'] = aggregated_invoices['weighted_interference_score'].apply(assign_rating)\n",
    "\n",
    "    # Merge aggregated invoices with contracts\n",
    "    df_contracts_filtered = df_contracts[\n",
    "        ['contract_name', 'parent_account_name', 'contract_value', 'start_date', 'end_date']\n",
    "    ].copy()\n",
    "    df_contracts_filtered['start_date'] = pd.to_datetime(df_contracts_filtered['start_date'], errors='coerce')\n",
    "    df_contracts_filtered['end_date'] = pd.to_datetime(df_contracts_filtered['end_date'], errors='coerce')\n",
    "\n",
    "    merged_data = pd.merge(\n",
    "        aggregated_invoices,\n",
    "        df_contracts_filtered,\n",
    "        on=\"contract_name\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Group by parent account name and calculate weighted scores\n",
    "    grouped_parent = merged_data.groupby(\"parent_account_name\")\n",
    "    parent_aggregated = grouped_parent.agg(\n",
    "        total_contract_count=(\"contract_name\", \"nunique\"),\n",
    "        total_contract_value=(\"contract_value\", \"sum\"),\n",
    "        total_invoice_count=(\"invoice_count\", \"sum\"),\n",
    "        total_amount_in_usd=(\"total_amount_in_usd\", \"sum\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # Weighted interference score for parent companies\n",
    "    def compute_parent_weighted_score(group):\n",
    "        if group[\"total_amount_in_usd\"].sum() > 0:\n",
    "            return (group[\"weighted_interference_score\"] * group[\"total_amount_in_usd\"]).sum() / group[\"total_amount_in_usd\"].sum()\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    parent_aggregated['weighted_interference_score'] = grouped_parent.apply(compute_parent_weighted_score).values\n",
    "    parent_aggregated['rating'] = parent_aggregated['weighted_interference_score'].apply(assign_rating)\n",
    "\n",
    "    # Drop 'total_contract_value' if present\n",
    "    parent_aggregated = parent_aggregated.drop(columns=['total_contract_value'], errors='ignore')\n",
    "\n",
    "    # ====================== Save Aggregated Data (unchanged logic) ======================\n",
    "    output_excel = r\"C:\\Users\\ak012\\Documents\\Projects\\Customers\\aggregated_parent_companies.xlsx\"\n",
    "    try:\n",
    "        parent_aggregated.to_excel(output_excel, index=False)\n",
    "        print(f\"Aggregated parent company data saved to {output_excel}\")\n",
    "    except PermissionError:\n",
    "        print(f\"PermissionError: Could not write to '{output_excel}'. \"\n",
    "              \"Please close the file or use a different path.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving Excel file: {e}\")\n",
    "\n",
    "    output_json = r\"C:\\Users\\ak012\\Documents\\Projects\\Customers\\aggregated_parent_companies.json\"\n",
    "    try:\n",
    "        parent_aggregated.to_json(output_json, orient=\"records\", date_format=\"iso\")\n",
    "        print(f\"Aggregated parent company data saved to {output_json}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving JSON file: {e}\")\n",
    "\n",
    "    # =============================================================================\n",
    "    #  NEW CODE: Insert ALL rows from merged_data (ensuring datetime fix for NaT).\n",
    "    #  We include ALL columns, do not drop anything.\n",
    "    # =============================================================================\n",
    "\n",
    "    df_for_db = merged_data.copy()\n",
    "\n",
    "    # If 'total_amount_in_usd' exists, rename to 'total_invoice_amount'\n",
    "    if \"total_amount_in_usd\" in df_for_db.columns:\n",
    "        df_for_db.rename(columns={\"total_amount_in_usd\": \"total_invoice_amount\"}, inplace=True)\n",
    "\n",
    "    # 1) Convert any datetime columns (including possibly NaT) to safe ISO strings or None\n",
    "    def date_to_string(dt):\n",
    "        if pd.isnull(dt):\n",
    "            return None\n",
    "        if isinstance(dt, datetime):\n",
    "            return dt.isoformat()  # or str(dt)\n",
    "        return str(dt)\n",
    "\n",
    "    # Apply date_to_string to all datetime columns\n",
    "    datetime_cols = df_for_db.select_dtypes(include=[\"datetimetz\", \"datetime64[ns]\"]).columns\n",
    "    for col in datetime_cols:\n",
    "        df_for_db[col] = df_for_db[col].apply(date_to_string)\n",
    "\n",
    "    # 2) Insert all rows into 'company_customers' without excluding any columns\n",
    "    try:\n",
    "        results = customers_collection.insert_many(df_for_db.to_dict(\"records\"))\n",
    "        print(\n",
    "            f\"Inserted {len(results.inserted_ids)} documents into 'company_customers' collection.\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting into 'company_customers': {e}\")\n",
    "\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    process_invoices_and_contracts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
